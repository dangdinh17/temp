{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:23:58.495030Z","iopub.status.busy":"2024-09-25T12:23:58.494308Z","iopub.status.idle":"2024-09-25T12:24:03.729522Z","shell.execute_reply":"2024-09-25T12:24:03.728566Z","shell.execute_reply.started":"2024-09-25T12:23:58.494992Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Số lượng tham số của mô hình: 664704\n"]}],"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import shutil\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.parallel import DataParallel\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torchvision.utils import save_image\n","\n","from tqdm import tqdm\n","\n","\n","from models.sr_model import *\n","from models.wdsr import *\n","from models.srresnet_ import *\n","from models.sr_model import *\n","from models.utils import *\n","from models.vdsr import *\n","from models.srcnn import *\n","import time\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.731452Z","iopub.status.busy":"2024-09-25T12:24:03.730941Z","iopub.status.idle":"2024-09-25T12:24:03.794823Z","shell.execute_reply":"2024-09-25T12:24:03.793839Z","shell.execute_reply.started":"2024-09-25T12:24:03.731417Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.797602Z","iopub.status.busy":"2024-09-25T12:24:03.797285Z","iopub.status.idle":"2024-09-25T12:24:03.821933Z","shell.execute_reply":"2024-09-25T12:24:03.821064Z","shell.execute_reply.started":"2024-09-25T12:24:03.797577Z"},"trusted":true},"outputs":[],"source":["# edsr_srcnn = EDSR_srcnnnnfy()\n","\n","# srresnet = SRResNet().to(device)\n","# srcnn = RCAN().to(device)\n","vdsr = VDSR().to(device)\n","srcnn = SRCNN().to(device)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","# # edsr_srcnna.load_state_dict(torch.load('weight/best_edsrx4_model.pth', map_location=device, weights_only=True))\n","# edsr_orig.load_state_dict(torch.load('weight/best_edsrx4_orig_model.pth', map_location=device))\n","# edrn_sobel.load_state_dict(torch.load('weight/best_sobel_srx4_model.pth', map_location=device))\n","# edrn_canny.load_state_dict(torch.load('weight/best_canny_srx4_model.pth', map_location=device))\n","# srresnet.load_state_dict(torch.load('weight/model_srresnet.pth', map_location=device))\n","# srcnn.load_state_dict(torch.load('weight/srcnn_x4.pth', map_location=device))\n","# vdsr.load_state_dict(torch.load('weight/vdsr_x4.pth', map_location=device))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.824325Z","iopub.status.busy":"2024-09-25T12:24:03.823331Z","iopub.status.idle":"2024-09-25T12:24:03.833160Z","shell.execute_reply":"2024-09-25T12:24:03.832215Z","shell.execute_reply.started":"2024-09-25T12:24:03.824292Z"},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = cv2.imread(os.path.join(self.lr_dir, self.lr_files[idx]))\n","        hr_image = cv2.imread(os.path.join(self.hr_dir, self.hr_files[idx]))\n","        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_BGR2RGB)\n","        hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)\n","        hr_height, hr_width = hr_image.shape[:2]\n","        # scale_factor = 4\n","        # lr_height, lr_width = height // 2, width // 2\n","        # hr_height, hr_width = height * 2, width * 2\n","\n","        # # Rescale ảnh LR lên 4 lần\n","        # lr_image = cv2.resize(lr_image, (lr_width, lr_height), interpolation=cv2.INTER_CUBIC)\n","        lr_image = cv2.resize(lr_image, (hr_width, hr_height), interpolation=cv2.INTER_CUBIC)\n","        \n","        # hr_image = cv2.resize(hr_image, (hr_width, hr_height), interpolation=cv2.INTER_CUBIC)\n","\n","        transform = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.ToTensor()\n","        ])\n","        \n","        lr_image = transform(lr_image)\n","        hr_image = transform(hr_image)\n","        return lr_image, hr_image\n","    \n","# class ImageDataset(Dataset):\n","    # def __init__(self, lr_dir, hr_dir):\n","    #     self.lr_files = sorted(os.listdir(lr_dir))\n","    #     self.hr_files = sorted(os.listdir(hr_dir))\n","    #     self.lr_dir = lr_dir\n","    #     self.hr_dir = hr_dir\n","\n","    # def __len__(self):\n","    #     return len(self.lr_files)\n","\n","    # def __getitem__(self, idx):\n","    #     lr_image = Image.open(os.path.join(self.lr_dir, self.lr_files[idx])).convert('RGB')\n","    #     hr_image = Image.open(os.path.join(self.hr_dir, self.hr_files[idx])).convert('RGB')\n","\n","    #     width, height = lr_image.size\n","        \n","    #     # Tính kích thước mới bằng cách nhân với scale_factor\n","    #     new_width = width * 4\n","    #     new_height = height * 4\n","\n","    #     # Resize ảnh LR lên theo kích thước mới\n","    #     lr_image = lr_image.resize((new_width, new_height), Image.BICUBIC)\n","\n","    #     hr_image = np.array(hr_image).astype(np.float32)\n","    #     lr_image = np.array(lr_image).astype(np.float32)\n","    #     hr_image = convert_rgb_to_y(hr_image)\n","    #     lr_image = convert_rgb_to_y(lr_image)\n","    #     hr_image = np.expand_dims(hr_image / 255., 0)\n","    #     lr_image = np.expand_dims(lr_image / 255., 0)\n","    #     transform = transforms.Compose([\n","    #         # transforms.ToPILImage(),\n","    #         transforms.ToTensor()\n","    #     ])\n","        \n","    #     # lr_image = transform(lr_image)\n","    #     # hr_image = transform(hr_image)\n","    #     return lr_image, hr_image"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.835254Z","iopub.status.busy":"2024-09-25T12:24:03.834750Z","iopub.status.idle":"2024-09-25T12:24:03.841602Z","shell.execute_reply":"2024-09-25T12:24:03.840600Z","shell.execute_reply.started":"2024-09-25T12:24:03.835180Z"},"trusted":true},"outputs":[],"source":["# Đường dẫn tới bộ dữ liệu\n","train_lr_dir = 'Train/LR'\n","train_hr_dir = 'Train/HR'\n","valid_lr_dir = 'Test/LR'\n","valid_hr_dir = 'Test/HR'\n","# test_hr_dir  = '/kaggle/input/srdataset/sr_data/test/HR'\n","# test_lr_dir  = '/kaggle/input/srdataset/sr_data/test/LR'\n","\n","# print(torch.cuda.memory_allocated())\n","# print(torch.cuda.memory_reserved())"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:29.152867Z","iopub.status.busy":"2024-09-25T12:33:29.152523Z","iopub.status.idle":"2024-09-25T12:33:30.352211Z","shell.execute_reply":"2024-09-25T12:33:30.351285Z","shell.execute_reply.started":"2024-09-25T12:33:29.152842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12500\n"]}],"source":["from torch.amp import autocast, GradScaler\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","train_dataset = ImageDataset(train_lr_dir, train_hr_dir)\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir)\n","valid_loader = DataLoader(valid_dataset)\n","\n","# vdsr_train_dataset = vdsrImageDataset(train_lr_dir, train_hr_dir)\n","# vdsr_train_loader = DataLoader(vdsr_train_dataset, batch_size = 16, shuffle=True)\n","\n","# vdsr_valid_dataset = vdsrImageDataset(valid_lr_dir, valid_hr_dir)\n","# vdsr_valid_loader = DataLoader(vdsr_valid_dataset)\n","print(len(train_loader))\n","\n","# Khởi tạo loss function\n","criterion = nn.MSELoss()\n","\n","# Khởi tạo optimizers, schedulers cho từng mô hình\n","# optim_edsr = optim.Adam(edsr_orig.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","# scheduler_edsr = optim.lr_scheduler.StepLR(optim_edsr, step_size=10**5, gamma=0.5)\n","\n","# optim_srresnet = optim.Adam(srresnet.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","# scheduler_srresnet = optim.lr_scheduler.StepLR(optim_srresnet, step_size=10**5, gamma=0.5)\n","\n","optim_srcnn = optim.Adam(srcnn.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","scheduler_srcnn = optim.lr_scheduler.StepLR(optim_srcnn, step_size=10**5, gamma=0.5)\n","\n","optim_vdsr = optim.Adam(vdsr.parameters(), lr=1e-4, betas=(0.9, 0.999))\n","scheduler_vdsr = optim.lr_scheduler.StepLR(optim_vdsr, step_size=10**5, gamma=0.5)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:31.506324Z","iopub.status.busy":"2024-09-25T12:33:31.505734Z","iopub.status.idle":"2024-09-25T12:33:31.511941Z","shell.execute_reply":"2024-09-25T12:33:31.510965Z","shell.execute_reply.started":"2024-09-25T12:33:31.506290Z"},"trusted":true},"outputs":[],"source":["def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Training"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:32.155872Z","iopub.status.busy":"2024-09-25T12:33:32.154884Z","iopub.status.idle":"2024-09-25T14:57:54.133761Z","shell.execute_reply":"2024-09-25T14:57:54.132406Z","shell.execute_reply.started":"2024-09-25T12:33:32.155839Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/24:   0%|          | 0/12500 [00:00<?, ?batch/s]/home/robot/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n","Epoch 1/24:   0%|          | 38/12500 [00:06<33:40,  6.17batch/s] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Training loop for srcnn\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhr_images\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhr_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhr_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[5], line 63\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     61\u001b[0m hr_image \u001b[38;5;241m=\u001b[39m convert_rgb_to_y(hr_image)\n\u001b[1;32m     62\u001b[0m lr_image \u001b[38;5;241m=\u001b[39m convert_rgb_to_y(lr_image)\n\u001b[0;32m---> 63\u001b[0m hr_image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhr_image\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m lr_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(lr_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     65\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# transforms.ToPILImage(),\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor()\n\u001b[1;32m     68\u001b[0m ])\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/numpy/lib/_shape_base_impl.py:504\u001b[0m, in \u001b[0;36m_expand_dims_dispatcher\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not returning \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man array of the correct shape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_expand_dims_dispatcher\u001b[39m(a, axis):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m    508\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_expand_dims_dispatcher)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexpand_dims\u001b[39m(a, axis):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Hàm tính PSNR\n","def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()\n","\n","num_epochs = 24\n","\n","best_psnr_srcnn = float('-inf')\n","best_psnr_vdsr = float('-inf')\n","torch.cuda.empty_cache()\n","\n","losses_srcnn = []\n","losses_vdsr = []\n","\n","avg_psnr_srcnn = []\n","avg_psnr_vdsr = []\n","\n","val_avg_psnr_srcnn = []\n","val_avg_psnr_vdsr = []\n","\n","patience = 50\n","epochs_no_improve = 0\n","log_file = open('training_log_models_srcnnn_vdsr.txt', 'a')\n","\n","for epoch in range(num_epochs):\n","    srcnn.train()\n","    vdsr.train()\n","\n","    epoch_loss_srcnn, psnr_values_srcnn = 0, 0\n","    epoch_loss_vdsr, psnr_values_vdsr = 0, 0\n","    start_time = time.time()\n","\n","    # Training loop for srcnn\n","    for (lr_images, hr_images) in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","        lr_images = lr_images.cuda()\n","        hr_images = hr_images.cuda()\n","\n","        # Train srcnn model\n","        optim_srcnn.zero_grad()\n","        with autocast(device_type='cuda'):\n","            outputs_srcnn =srcnn(lr_images)\n","            loss_srcnn = criterion(outputs_srcnn, hr_images)\n","        psnr_srcnn = calculate_psnr(outputs_srcnn, hr_images)\n","\n","        scaler.scale(loss_srcnn).backward()\n","        scaler.step(optim_srcnn)\n","        scaler.update()\n","        scheduler_srcnn.step()\n","\n","        epoch_loss_srcnn += loss_srcnn.item()\n","        psnr_values_srcnn += psnr_srcnn\n","\n","        optim_vdsr.zero_grad()\n","        with autocast(device_type='cuda'):\n","            outputs_vdsr = vdsr(lr_images)\n","            loss_vdsr = criterion(outputs_vdsr, hr_images)\n","        psnr_vdsr = calculate_psnr(outputs_vdsr, hr_images)\n","\n","        scaler.scale(loss_vdsr).backward()\n","        scaler.step(optim_vdsr)\n","        scaler.update()\n","        scheduler_vdsr.step()\n","\n","        epoch_loss_vdsr += loss_vdsr.item()\n","        psnr_values_vdsr += psnr_vdsr\n","      \n","    # Training loop for vdsr\n","   \n","        \n","    # Average losses and PSNRs\n","    avg_epoch_loss_srcnn = epoch_loss_srcnn / len(train_loader)\n","    avg_psnr_srcnn_epoch = psnr_values_srcnn / len(train_loader)\n","    losses_srcnn.append(avg_epoch_loss_srcnn)\n","    avg_psnr_srcnn.append(avg_psnr_srcnn_epoch)\n","\n","    avg_epoch_loss_vdsr = epoch_loss_vdsr / len(train_loader)\n","    avg_psnr_vdsr_epoch = psnr_values_vdsr / len(train_loader)\n","    losses_vdsr.append(avg_epoch_loss_vdsr)\n","    avg_psnr_vdsr.append(avg_psnr_vdsr_epoch)\n","\n","    # Validation for srcnn and vdsr\n","    srcnn.eval()\n","    vdsr.eval()\n","\n","    val_psnr_srcnn, val_psnr_vdsr = 0, 0\n","\n","    with torch.no_grad():\n","        # Validate srcnn\n","        for (lr_images, hr_images) in valid_loader:\n","            lr_images = lr_images.cuda()\n","            hr_images = hr_images.cuda()\n","\n","            outputs_srcnn = srcnn(lr_images)\n","            psnr_srcnn = calculate_psnr(outputs_srcnn, hr_images)\n","            val_psnr_srcnn += psnr_srcnn\n","\n","\n","            outputs_vdsr = vdsr(lr_images)\n","            psnr_vdsr = calculate_psnr(outputs_vdsr, hr_images)\n","            val_psnr_vdsr += psnr_vdsr\n","        # Validate vdsr\n","        \n","\n","\n","    val_avg_psnr_srcnn_epoch = val_psnr_srcnn / len(valid_loader)\n","    val_avg_psnr_srcnn.append(val_avg_psnr_srcnn_epoch)\n","\n","    val_avg_psnr_vdsr_epoch = val_psnr_vdsr / len(valid_loader)\n","    val_avg_psnr_vdsr.append(val_avg_psnr_vdsr_epoch)\n","\n","    # Save best model for srcnn\n","    if val_avg_psnr_srcnn_epoch > best_psnr_srcnn:\n","        best_psnr_srcnn = val_avg_psnr_srcnn_epoch\n","        torch.save(srcnn.state_dict(), 'best_wdsra.pth')\n","        print(f\"Saved SRCNN model with PSNR {best_psnr_srcnn:.4f}\")\n","    # Save best model for vdsr\n","    if val_avg_psnr_vdsr_epoch > best_psnr_vdsr:\n","        best_psnr_vdsr = val_avg_psnr_vdsr_epoch\n","        torch.save(vdsr.state_dict(), 'best_vdsr.pth')\n","        print(f\"Saved VDSR model with PSNR {best_psnr_vdsr:.4f}\")\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] completed: WDSRA Loss: {avg_epoch_loss_srcnn:.4f}, PSNR: {avg_psnr_srcnn_epoch:.4f}, Validation PSNR: {val_avg_psnr_srcnn_epoch:.4f}\")\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] completed: vdsr Loss: {avg_epoch_loss_vdsr:.4f}, PSNR: {avg_psnr_vdsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_vdsr_epoch:.4f}\")\n","\n","    log_file.write(f\"Epoch {epoch+1}: WDSRA PSNR: {avg_psnr_srcnn_epoch:.4f}, Validation PSNR: {val_avg_psnr_srcnn_epoch:.4f}\\n\")\n","    log_file.write(f\"Epoch {epoch+1}: vdsr PSNR: {avg_psnr_vdsr_epoch:.4f}, Validation PSNR: {val_avg_psnr_vdsr_epoch:.4f}\\n\")\n","\n","    # log_file.flush()\n","\n","log_file.close()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T12:24:11.228342Z","iopub.status.idle":"2024-09-25T12:24:11.228692Z","shell.execute_reply":"2024-09-25T12:24:11.228542Z","shell.execute_reply.started":"2024-09-25T12:24:11.228528Z"},"trusted":true},"outputs":[],"source":["# Tải và chuyển đổi ảnh\n","transform = transforms.ToTensor()\n","output_image_dir = 'output/images'\n","os.makedirs(output_image_dir, exist_ok = True)\n","# Duyệt qua các ảnh trong thư mục\n","lr_image_files = os.listdir(test_lr_dir)\n","hr_image_files = os.listdir(test_hr_dir)\n","lr_image_files.sort()\n","hr_image_files.sort()\n","psnr_values_sobel = []\n","psnr_values_canny = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T12:24:11.229549Z","iopub.status.idle":"2024-09-25T12:24:11.229851Z","shell.execute_reply":"2024-09-25T12:24:11.229713Z","shell.execute_reply.started":"2024-09-25T12:24:11.229700Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi\n","with torch.no_grad():\n","    for lr_image_file, hr_image_file in tqdm(zip(lr_image_files, hr_image_files), unit = 'batch'):\n","        # Đường dẫn đến ảnh\n","        lr_image_path = os.path.join(test_lr_dir, lr_image_file)\n","        hr_image_path = os.path.join(test_hr_dir, hr_image_file)\n","        output_image_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_edsrx4.jpg')\n","\n","        # Tải và chuyển đổi ảnh\n","        lr_image = Image.open(lr_image_path)\n","        hr_image = Image.open(hr_image_path)\n","\n","        lr_image = transform(lr_image).unsqueeze(0).cuda()  # Thêm batch dimension và chuyển sang CPU\n","        hr_image = transform(hr_image).unsqueeze(0).cuda()  # Thêm batch dimension và chuyển sang CPU\n","\n","        # Dự đoán\n","        sobel = sobelsr(lr_image)\n","#         canny = cannysr(lr_image)\n","\n","        # Tính toán PSNR\n","        psnr_sobel = calculate_psnr(sobel, hr_image)\n","#         psnr_canny = calculate_psnr(canny, hr_image)\n","\n","        psnr_values_sobel.append(psnr_sobel)\n","#         psnr_values_canny.append(psnr_canny)\n","\n","#         # Chuyển đổi tensor đầu ra thành ảnh và lưu\n","#         output_image = output.squeeze(0).cuda()  # Loại bỏ batch dimension và chuyển tensor sang CPU\n","#         output_image = transforms.ToPILImage()(output_image)  # Chuyển tensor thành ảnh PIL\n","#         output_image.save(output_image_path)  # Lưu ảnh\n","\n","# Tính toán PSNR trung bình\n","average_psnr_sobel = sum(psnr_values_sobel) / len(psnr_values_sobel)\n","print(f\"Average PSNR sobel: {average_psnr_sobel:.2f} dB\")\n","\n","# average_psnr_canny = sum(psnr_values_canny) / len(psnr_values_canny)\n","# print(f\"Average PSNR canny: {average_psnr_canny:.2f} dB\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5414450,"sourceId":8989742,"sourceType":"datasetVersion"},{"datasetId":5671931,"sourceId":9356096,"sourceType":"datasetVersion"},{"datasetId":5764801,"sourceId":9478075,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
