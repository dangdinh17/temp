{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from models.srcnn import *\n",
    "from models.vdsr import *\n",
    "\n",
    "from models.sr_model import *\n",
    "from models.edrn import *\n",
    "from models.vdsr import *\n",
    "from models.srresnet_ import *\n",
    "from models.sr_model import *\n",
    "from models.vdsr import *\n",
    "from models.utils import *\n",
    "from models.srcnn import *\n",
    "from models.edsr import *\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edsr_srcnn = EDSR_srcnnfy()\n",
    "edsr = EDSR().to(device)\n",
    "edrn_canny = EDRN(use_canny=True).to(device)\n",
    "edrn_sobel = EDRN(use_sobel=True).to(device)\n",
    "srresnet = SRResNet().to(device)\n",
    "vdsr = VDSR().to(device)\n",
    "srcnn = SRCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/tmp/ipykernel_149750/957710577.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edsr.load_state_dict(torch.load('best_edsr.pth', map_location=device))\n",
      "/tmp/ipykernel_149750/957710577.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edrn_sobel.load_state_dict(torch.load('weight_pcb/best_sobel_srx4_model.pth', map_location=device))\n",
      "/tmp/ipykernel_149750/957710577.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edrn_canny.load_state_dict(torch.load('weight_pcb/best_canny_srx4_model.pth', map_location=device))\n",
      "/tmp/ipykernel_149750/957710577.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  srresnet.load_state_dict(torch.load('best_srresnet.pth', map_location=device))\n",
      "/tmp/ipykernel_149750/957710577.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vdsr.load_state_dict(torch.load('weight_pcb/best_vdsr.pth', map_location=device))\n",
      "/tmp/ipykernel_149750/957710577.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  srcnn.load_state_dict(torch.load('weight_pcb/best_srcnn.pth', map_location=device))\n"
=======
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edsr.load_state_dict(torch.load('weight/best_edsr.pth', map_location=device))\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edrn_sobel.load_state_dict(torch.load('weight/best_sobel_srx4_model.pth', map_location=device))\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  edrn_canny.load_state_dict(torch.load('weight/best_canny_srx4_model.pth', map_location=device))\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  srresnet.load_state_dict(torch.load('weight/best_srresnet.pth', map_location=device))\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vdsr.load_state_dict(torch.load('weight/best_vdsr.pth', map_location=device))\n",
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_7796\\1166636198.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  srcnn.load_state_dict(torch.load('weight/best_srcnn.pth', map_location=device))\n"
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
<<<<<<< HEAD
    "edsr.load_state_dict(torch.load('best_edsr.pth', map_location=device))\n",
    "edrn_sobel.load_state_dict(torch.load('weight_pcb/best_sobel_srx4_model.pth', map_location=device))\n",
    "edrn_canny.load_state_dict(torch.load('weight_pcb/best_canny_srx4_model.pth', map_location=device))\n",
    "srresnet.load_state_dict(torch.load('best_srresnet.pth', map_location=device))\n",
    "vdsr.load_state_dict(torch.load('weight_pcb/best_vdsr.pth', map_location=device))\n",
    "srcnn.load_state_dict(torch.load('weight_pcb/best_srcnn.pth', map_location=device))\n"
=======
    "edsr.load_state_dict(torch.load('weight/best_edsr.pth', map_location=device))\n",
    "edrn_sobel.load_state_dict(torch.load('weight/best_sobel_srx4_model.pth', map_location=device))\n",
    "edrn_canny.load_state_dict(torch.load('weight/best_canny_srx4_model.pth', map_location=device))\n",
    "srresnet.load_state_dict(torch.load('weight/best_srresnet.pth', map_location=device))\n",
    "vdsr.load_state_dict(torch.load('weight/best_vdsr.pth', map_location=device))\n",
    "srcnn.load_state_dict(torch.load('weight/best_srcnn.pth', map_location=device))\n"
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "\n",
    "def calculate_metrics(img1, img2, max_pixel_value=1.0):\n",
    "    psnr = PeakSignalNoiseRatio(data_range=1.0)\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "    psnr_value = psnr(img1, img2)\n",
    "    ssim_value = ssim(img1, img2)\n",
    "    return psnr_value, ssim_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, type =False):\n",
    "        self.lr_files = sorted(os.listdir(lr_dir))\n",
    "        self.hr_files = sorted(os.listdir(hr_dir))\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.type =type\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_image = cv2.imread(os.path.join(self.lr_dir, self.lr_files[idx]))\n",
    "        hr_image = cv2.imread(os.path.join(self.hr_dir, self.hr_files[idx]))\n",
    "        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_BGR2RGB)\n",
    "        hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)\n",
    "        if self.type:\n",
    "            height, width = lr_image.shape[:2]\n",
    "            scale_factor = 4\n",
    "            # lr_height, lr_width = height // 2, width // 2\n",
    "            hr_height, hr_width = height * 4, width * 4\n",
    "\n",
    "            # # Rescale ảnh LR lên 4 lần\n",
    "            # lr_image = cv2.resize(lr_image, (lr_width, lr_height), interpolation=cv2.INTER_CUBIC)\n",
    "            lr_image = cv2.resize(lr_image, (hr_width, hr_height), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "        # hr_image = cv2.resize(hr_image, (hr_width, hr_height), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        lr_image = transform(lr_image)\n",
    "        hr_image = transform(hr_image)\n",
    "        return lr_image, hr_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'benchmark/DIV2K/LR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m valid_hr_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/HR\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m output_image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark/output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_lr_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_hr_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m valid_dataset_2 \u001b[38;5;241m=\u001b[39m ImageDataset(valid_lr_dir, valid_hr_dir, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(valid_dataset)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mImageDataset.__init__\u001b[0;34m(self, lr_dir, hr_dir, type)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr_dir, hr_dir, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhr_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(hr_dir))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_dir \u001b[38;5;241m=\u001b[39m lr_dir\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'benchmark/DIV2K/LR'"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [08:42<00:00, 52.25s/batch]\n",
      "100%|██████████| 10/10 [07:41<00:00, 46.19s/batch]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
     ]
    }
   ],
   "source": [
    "import time\n",
    "sub = 'DIV2K'\n",
    "valid_lr_dir = f'benchmark/{sub}/LR'\n",
    "valid_hr_dir = f'benchmark/{sub}/HR'\n",
    "output_image_dir = f'benchmark/output/{sub}'\n",
    "valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir)\n",
    "valid_dataset_2 = ImageDataset(valid_lr_dir, valid_hr_dir, type = True)\n",
    "valid_loader = DataLoader(valid_dataset)\n",
    "valid_loader_2 = DataLoader(valid_dataset_2)\n",
    "log_file = open('subtracttion.txt', 'a')\n",
    "log_file.write(f'{sub}\\n')\n",
    "# Đo thời gian xử lý trung bình cho từng mô hình\n",
    "sobel_total_time = 0\n",
    "canny_total_time = 0\n",
    "edsr_total_time = 0\n",
    "srresnet_total_time = 0\n",
    "vdsr_total_time = 0\n",
    "srcnn_total_time = 0\n",
    "bicubic_total_time = 0\n",
    "\n",
    "edrn_sobel.eval()\n",
    "edrn_canny.eval()\n",
    "srresnet.eval()\n",
    "srcnn.eval()\n",
    "edsr.eval()\n",
    "vdsr.eval()\n",
    "\n",
    "val_psnr_values_bicubic = 0\n",
    "val_psnr_values_sobel = 0\n",
    "val_psnr_values_canny = 0\n",
    "val_psnr_values_edsr = 0\n",
    "val_psnr_values_srresnet = 0\n",
    "val_psnr_values_vdsr = 0\n",
    "val_psnr_values_srcnn = 0\n",
    "\n",
    "val_ssim_values_sobel = 0\n",
    "val_ssim_values_canny = 0\n",
    "val_ssim_values_edsr = 0\n",
    "val_ssim_values_srresnet = 0\n",
    "val_ssim_values_vdsr = 0\n",
    "val_ssim_values_srcnn = 0\n",
    "val_ssim_values_bicubic = 0\n",
    "\n",
<<<<<<< HEAD
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():  # Không tính toán gradient trong quá trình validation\n",
    "    for (lr_images, hr_images) in tqdm(valid_loader_2, unit='batch'):\n",
    "        # VDSR validation\n",
    "        start_time = time.time()\n",
    "        outputs_vdsr = vdsr(lr_images)\n",
    "        vdsr_total_time += time.time() - start_time\n",
    "        psnr_vdsr, ssim_vdsr = calculate_metrics(outputs_vdsr, hr_images)\n",
    "\n",
    "        # SRCNN validation\n",
    "        start_time = time.time()\n",
    "        outputs_srcnn = srcnn(lr_images)\n",
    "        srcnn_total_time += time.time() - start_time\n",
    "        psnr_srcnn, ssim_srcnn = calculate_metrics(outputs_srcnn, hr_images)\n",
    "\n",
    "        # Cập nhật PSNR và SSIM cho VDSR và SRCNN\n",
    "        val_psnr_values_vdsr += psnr_vdsr\n",
    "        val_psnr_values_srcnn += psnr_srcnn\n",
    "\n",
    "        val_ssim_values_vdsr += ssim_vdsr\n",
    "        val_ssim_values_srcnn += ssim_srcnn\n",
    "\n",
    "    # Tính PSNR và SSIM trung bình cho VDSR và SRCNN\n",
    "    val_average_psnr_vdsr = val_psnr_values_vdsr / len(valid_loader_2)\n",
    "    val_average_psnr_srcnn = val_psnr_values_srcnn / len(valid_loader_2)\n",
    "\n",
    "    val_average_ssim_vdsr = val_ssim_values_vdsr / len(valid_loader_2)\n",
    "    val_average_ssim_srcnn = val_ssim_values_srcnn / len(valid_loader_2)\n",
    "\n",
    "    # Thời gian xử lý trung bình cho VDSR và SRCNN\n",
    "    avg_time_vdsr = vdsr_total_time / len(valid_loader_2)\n",
    "    avg_time_srcnn = srcnn_total_time / len(valid_loader_2)\n",
    "\n",
    "    # Ghi kết quả vào log_file\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():  # Không tính toán gradient trong quá trình validation\n",
=======
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():  # Không tính toán gradient trong quá trình validation\n",
    "    for (lr_images, hr_images) in tqdm(valid_loader_2, unit='batch'):\n",
    "        # VDSR validation\n",
    "        start_time = time.time()\n",
    "        outputs_vdsr = vdsr(lr_images)\n",
    "        vdsr_total_time += time.time() - start_time\n",
    "        psnr_vdsr, ssim_vdsr = calculate_metrics(outputs_vdsr, hr_images)\n",
    "\n",
    "        # SRCNN validation\n",
    "        start_time = time.time()\n",
    "        outputs_srcnn = srcnn(lr_images)\n",
    "        srcnn_total_time += time.time() - start_time\n",
    "        psnr_srcnn, ssim_srcnn = calculate_metrics(outputs_srcnn, hr_images)\n",
    "\n",
    "        # Cập nhật PSNR và SSIM cho VDSR và SRCNN\n",
    "        val_psnr_values_vdsr += psnr_vdsr\n",
    "        val_psnr_values_srcnn += psnr_srcnn\n",
    "\n",
    "        val_ssim_values_vdsr += ssim_vdsr\n",
    "        val_ssim_values_srcnn += ssim_srcnn\n",
    "\n",
    "    # Tính PSNR và SSIM trung bình cho VDSR và SRCNN\n",
    "    val_average_psnr_vdsr = val_psnr_values_vdsr / len(valid_loader_2)\n",
    "    val_average_psnr_srcnn = val_psnr_values_srcnn / len(valid_loader_2)\n",
    "\n",
    "    val_average_ssim_vdsr = val_ssim_values_vdsr / len(valid_loader_2)\n",
    "    val_average_ssim_srcnn = val_ssim_values_srcnn / len(valid_loader_2)\n",
    "\n",
    "    # Thời gian xử lý trung bình cho VDSR và SRCNN\n",
    "    avg_time_vdsr = vdsr_total_time / len(valid_loader_2)\n",
    "    avg_time_srcnn = srcnn_total_time / len(valid_loader_2)\n",
    "\n",
    "    # Ghi kết quả vào log_file\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():  # Không tính toán gradient trong quá trình validation\n",
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
    "    for (lr_images, hr_images) in tqdm(valid_loader, unit='batch'):\n",
    "        lr_images = lr_images.to(device)\n",
    "        hr_images = hr_images.to(device)\n",
    "\n",
    "        # Sobel SR validation (không tính loss, chỉ tính PSNR và SSIM)\n",
    "        start_time = time.time()  # Đo thời gian bắt đầu\n",
    "        outputs_sobel = edrn_sobel(lr_images)\n",
    "        sobel_total_time += time.time() - start_time  # Tính thời gian xử lý\n",
    "        psnr_sobel, ssim_sobel = calculate_metrics(outputs_sobel, hr_images)\n",
    "\n",
    "        #bicubic\n",
    "        start_time = time.time()  # Đo thời gian bắt đầu\n",
    "        outputs_bicubic = F.interpolate(lr_images, scale_factor=4, mode='bilinear', align_corners=False)\n",
    "        bicubic_total_time += time.time() - start_time  # Tính thời gian xử lý bicubic\n",
    "        psnr_bicubic, ssim_bicubic = calculate_metrics(outputs_bicubic, hr_images)\n",
    "\n",
    "        # Canny SR validation\n",
    "        start_time = time.time()\n",
    "        outputs_canny = edrn_canny(lr_images)\n",
    "        canny_total_time += time.time() - start_time\n",
    "        psnr_canny, ssim_canny = calculate_metrics(outputs_canny, hr_images)\n",
    "\n",
    "        # EDSR SR validation\n",
    "        start_time = time.time()\n",
    "        outputs_edsr = edsr(lr_images)\n",
    "        edsr_total_time += time.time() - start_time\n",
    "        psnr_edsr, ssim_edsr = calculate_metrics(outputs_edsr, hr_images)\n",
    "\n",
    "        # SRResNet SR validation\n",
    "        start_time = time.time()\n",
    "        outputs_srresnet = srresnet(lr_images)\n",
    "        srresnet_total_time += time.time() - start_time\n",
    "        psnr_srresnet, ssim_srresnet = calculate_metrics(outputs_srresnet, hr_images)\n",
    "\n",
    "        # Cập nhật PSNR và SSIM\n",
    "        val_psnr_values_sobel += psnr_sobel\n",
    "        val_psnr_values_canny += psnr_canny\n",
    "        val_psnr_values_edsr += psnr_edsr\n",
    "        val_psnr_values_srresnet += psnr_srresnet\n",
    "        val_psnr_values_bicubic += psnr_bicubic\n",
    "        \n",
    "        val_ssim_values_sobel += ssim_sobel\n",
    "        val_ssim_values_canny += ssim_canny\n",
    "        val_ssim_values_edsr += ssim_edsr\n",
    "        val_ssim_values_srresnet += ssim_srresnet\n",
    "        val_ssim_values_bicubic += ssim_bicubic\n",
    "    # Tính PSNR và SSIM trung bình\n",
    "    val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n",
    "    val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n",
    "    val_average_psnr_edsr = val_psnr_values_edsr / len(valid_loader)\n",
    "    val_average_psnr_srresnet = val_psnr_values_srresnet / len(valid_loader)\n",
    "    val_average_psnr_bicubic = val_psnr_values_bicubic / len(valid_loader)\n",
    "    \n",
    "    val_average_ssim_sobel = val_ssim_values_sobel / len(valid_loader)\n",
    "    val_average_ssim_canny = val_ssim_values_canny / len(valid_loader)\n",
    "    val_average_ssim_edsr = val_ssim_values_edsr / len(valid_loader)\n",
    "    val_average_ssim_srresnet = val_ssim_values_srresnet / len(valid_loader)\n",
    "    val_average_ssim_bicubic = val_ssim_values_bicubic / len(valid_loader)\n",
    "\n",
    "    # Thời gian xử lý trung bình\n",
    "    avg_time_sobel = sobel_total_time / len(valid_loader)\n",
    "    avg_time_canny = canny_total_time / len(valid_loader)\n",
    "    avg_time_edsr = edsr_total_time / len(valid_loader)\n",
    "    avg_time_srresnet = srresnet_total_time / len(valid_loader)\n",
    "    avg_time_bicubic = bicubic_total_time / len(valid_loader)\n",
    "    \n",
    "\n",
    "    # Thời gian xử lý trung bình cho Bicubic\n",
    "    \n",
    "    temp_psnr = val_average_psnr_bicubic\n",
    "    temp_ssim = val_average_ssim_bicubic\n",
    "    # Ghi kết quả vào log_file\n",
    "    # Validation cho VDSR và SRCNN\n",
    "log_file.write(f'Bicubic:  SSIM / PSNR {val_average_ssim_bicubic:.4f} / {val_average_psnr_bicubic:.2f}, Time {avg_time_bicubic:.4f}s\\n')\n",
    "log_file.write(f'VDSR:  SSIM / PSNR {val_average_ssim_vdsr:.4f} / {val_average_psnr_vdsr:.2f}, Time {avg_time_vdsr:.4f}s\\n')\n",
    "log_file.write(f'SRCNN:  SSIM / PSNR {val_average_ssim_srcnn:.4f} / {val_average_psnr_srcnn:.2f}, Time {avg_time_srcnn:.4f}s\\n')    \n",
    "log_file.write(f'SRResNet:  SSIM / PSNR {val_average_ssim_srresnet:.4f} / {val_average_psnr_srresnet:.2f}, Time {avg_time_srresnet:.4f}s\\n')\n",
    "log_file.write(f'EDSR:  SSIM / PSNR {val_average_ssim_edsr:.4f} / {val_average_psnr_edsr:.2f}, Time {avg_time_edsr:.4f}s\\n')\n",
    "log_file.write(f'Sobel:  SSIM / PSNR {val_average_ssim_sobel:.4f} / {val_average_psnr_sobel:.2f}, Time {avg_time_sobel:.4f}s\\n')\n",
    "log_file.write(f'Canny:  SSIM / PSNR {val_average_ssim_canny:.4f} / {val_average_psnr_canny:.2f}, Time {avg_time_canny:.4f}s\\n')\n",
    "\n",
    "log_file.flush()\n",
    "log_file.close\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'benchmark/pcb/LR'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# index = random.randint(0, len(os.listdir(lr_image_dir))-1)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# file = '0875.png'\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# lr_image_file = file\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# hr_image_file = file\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (lr_image_file, hr_image_file) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr_image_dir\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(hr_image_dir))):\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Đường dẫn đến ảnh\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         lr_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(lr_image_dir, lr_image_file)\n\u001b[1;32m     23\u001b[0m         hr_image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(hr_image_dir, hr_image_file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'benchmark/pcb/LR'"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "c:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m output_srresnet \u001b[38;5;241m=\u001b[39m srresnet(lr_image)\n\u001b[0;32m    101\u001b[0m output_srcnn \u001b[38;5;241m=\u001b[39m srcnn(bicubic_)\n\u001b[1;32m--> 102\u001b[0m output_vdsr \u001b[38;5;241m=\u001b[39m \u001b[43mvdsr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbicubic_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEDSR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEDRN Sobel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEDRN Canny\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSRResNet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSRCNN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVDSR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    104\u001b[0m psnr_value \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Lưu giá trị PSNR cho mỗi mô hình\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mt:\\university_course\\project\\PCB-Defect-Detection-Ver-2\\models\\vdsr.py:36\u001b[0m, in \u001b[0;36mVDSR.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput(x))\n\u001b[1;32m---> 36\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresidual_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(out)\n\u001b[0;32m     38\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(out,residual)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mt:\\university_course\\project\\PCB-Defect-Detection-Ver-2\\models\\vdsr.py:12\u001b[0m, in \u001b[0;36mConv_ReLU_Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\envs\\env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from PIL import ImageDraw\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "sub = 'pcb'\n",
    "box = 80\n",
    "valid_lr_dir = f'benchmark/{sub}/LR'\n",
    "valid_hr_dir = f'benchmark/{sub}/HR'\n",
    "output_image_dir = f'benchmark/output/{sub}'\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "lr_image_dir = valid_lr_dir\n",
    "hr_image_dir = valid_hr_dir\n",
    "# index = random.randint(0, len(os.listdir(lr_image_dir))-1)\n",
    "# file = '0875.png'\n",
    "# lr_image_file = file\n",
    "# hr_image_file = file\n",
    "with torch.no_grad():\n",
    "    for (lr_image_file, hr_image_file) in zip(sorted(os.listdir(lr_image_dir)), sorted(os.listdir(hr_image_dir))):\n",
    "        # Đường dẫn đến ảnh\n",
    "\n",
    "        lr_image_path = os.path.join(lr_image_dir, lr_image_file)\n",
    "        hr_image_path = os.path.join(hr_image_dir, hr_image_file)\n",
    "        ####################################\n",
    "        img = cv2.imread(hr_image_path)  # Thay bằng đường dẫn ảnh của bạn\n",
    "        cv2.namedWindow(\"Image\")\n",
    "        cv2.imshow(\"Image\", img)\n",
    "        drawing = False  # True khi đang nhấn chuột\n",
    "        top_left_corner = [0,0]\n",
    "        xy = [0, 0, 0, 0]\n",
    "        def draw_rectangle(event, x, y, flags, param):\n",
    "            global drawing, top_left_corner, img, xy\n",
    "            \n",
    "            # Khi nhấn chuột trái, bắt đầu vẽ\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                drawing = True\n",
    "                top_left_corner = [x, y]   # Lưu tọa độ của điểm bắt đầu\n",
    "            \n",
    "            # Khi thả chuột trái, kết thúc vẽ\n",
    "            elif event == cv2.EVENT_LBUTTONUP:\n",
    "                drawing = False\n",
    "                \n",
    "                xy[0] = top_left_corner[0]\n",
    "                xy[1] = top_left_corner[1]\n",
    "                xy[2] = top_left_corner[0] + box # type: ignore\n",
    "                xy[3] = top_left_corner[1] + box\n",
    "                \n",
    "                cv2.destroyAllWindows()\n",
    "                # Đóng cửa sổ ảnh sau khi vẽ xong\n",
    "        # Đặt callback cho sự kiện chuột\n",
    "        cv2.setMouseCallback(\"Image\", draw_rectangle)\n",
    "\n",
    "        # Hiển thị ảnh và đợi cho đến khi bounding box được vẽ\n",
    "        cv2.waitKey(0)\n",
    "        ####################################\n",
    "        edsr_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_edsr.jpg')\n",
    "        edrn_sobel_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_edrn_sobel.jpg')\n",
    "        edrn_canny_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_edrn_canny.jpg')\n",
    "        bicubic_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_bicubic.jpg')\n",
    "        srresnet_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_srresnet.jpg')\n",
    "        srcnn_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_srcnn.jpg')\n",
    "        vdsr_path = os.path.join(output_image_dir, lr_image_file[:-4] + '_vdsr.jpg')\n",
    "\n",
    "        hr_path = os.path.join(output_image_dir, hr_image_file)\n",
    "        # Tải và chuyển đổi ảnh\n",
    "        lr_image = Image.open(lr_image_path)\n",
    "        hr_image = Image.open(hr_image_path)\n",
    "        w, h = hr_image.size\n",
    "        bicubic = lr_image.resize((w, h))\n",
    "        lr_image_copy = lr_image.copy().convert('RGB')\n",
    "        hr_image_copy = hr_image.copy()\n",
    "        # lr_image_1dms = torch.Tensor(lr_image_1dms)\n",
    "        lr_image = transform(lr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang CPU\n",
    "        hr_image = transform(hr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang CPU\n",
    "        bicubic_ = transform(bicubic).unsqueeze(0).to(device)\n",
    "        # print(type(lr_image_1dms))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # bicubic = lr_image_copy.resize((600, 600), resample=Image.BICUBIC) # type: ignore\n",
    "        # bicubic_ = transform(bicubic).unsqueeze(0).to(device)\n",
    "        # lr_image_1dms, _ = preprocess(lr_image_copy, device)\n",
    "        # lr_image_copy, _ = preprocess(lr_image_copy, device)\n",
    "        # hr_image_copy, _ = preprocess(HR, device)\n",
    "        # _, ycbcr = preprocess(bicubic, device)\n",
    "        time_pro = []\n",
    "        def measure_inference_time(model, input_image, model_name):\n",
    "            start_time = time.time()\n",
    "            output = model(input_image)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            inference_time = end_time - start_time\n",
    "            time_pro.append(inference_time)\n",
    "            return output\n",
    "        \n",
    "        # Dự đoán\n",
    "        output_edsr = edsr(lr_image)\n",
    "        output_edrn_sobel = edrn_sobel(lr_image)\n",
    "        output_edrn_canny = edrn_canny(lr_image)\n",
    "        output_srresnet = srresnet(lr_image)\n",
    "        output_srcnn = srcnn(bicubic_)\n",
    "        output_vdsr = vdsr(bicubic_)\n",
    "        models = ['EDSR', 'EDRN Sobel', 'EDRN Canny', 'SRResNet', 'SRCNN', 'VDSR']\n",
    "        psnr_value = []  # Lưu giá trị PSNR cho mỗi mô hình\n",
    "        ssim_value = []\n",
    "        # Tính PSNR cho từng mô hình (giả sử output của các mô hình đã có)\n",
    "        for model_output in [output_edsr, output_edrn_sobel, output_edrn_canny, output_srresnet, output_srcnn, output_vdsr]:\n",
    "            # Tính PSNR và thêm vào danh sách\n",
    "            psnr_value.append(calculate_metrics(model_output, hr_image)[0])\n",
    "            ssim_value.append(calculate_metrics(model_output, hr_image)[1])\n",
    "        # Ghi PSNR cho từng mô hình vào file\n",
    "        with open(f\"{output_image_dir}/results.txt\", \"a\") as psnr_file:\n",
    "            psnr_file.write(f\"HR Image: {hr_image_file}\\n\")\n",
    "            for i, model_name in enumerate(models):\n",
    "                psnr_file.write(f\"{model_name} PSNR/SSIM: {psnr_value[i]:.2f} dB/ {ssim_value[i]:.4f}\\n\")\n",
    "            psnr_file.write(f\"Bicubic PSNR/SSIM: {calculate_metrics(bicubic_, hr_image)[0]:.2f} dB/ {calculate_metrics(bicubic_, hr_image)[1]:.2f}\\n\")\n",
    "            psnr_file.write(\"\\n\")  # Dòng trống giữa các lần lặp\n",
    "            \n",
    "            \n",
    "        output_image_edsr = output_edsr.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_edsr = transforms.ToPILImage()(output_image_edsr)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_edsr = output_image_edsr.crop(xy)\n",
    "        output_image_edsr.resize((100, 100))\n",
    "        output_image_edsr.save(edsr_path)  # Lưu ảnh\n",
    "        \n",
    "        output_image_edrn_sobel = output_edrn_sobel.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_edrn_sobel = transforms.ToPILImage()(output_image_edrn_sobel)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_edrn_sobel = output_image_edrn_sobel.crop(xy)\n",
    "        output_image_edrn_sobel.resize((100, 100))\n",
    "        output_image_edrn_sobel.save(edrn_sobel_path)  # Lưu ảnh\n",
    "        \n",
    "        \n",
    "        output_image_edrn_canny = output_edrn_canny.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_edrn_canny = transforms.ToPILImage()(output_image_edrn_canny)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_edrn_canny = output_image_edrn_canny.crop(xy)\n",
    "        output_image_edrn_canny.resize((100, 100))\n",
    "        output_image_edrn_canny.save(edrn_canny_path)  # Lưu ảnh\n",
    "        \n",
    "        output_image_srcnn = output_srcnn.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_srcnn = transforms.ToPILImage()(output_image_srcnn)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_srcnn = output_image_srcnn.crop(xy)\n",
    "        output_image_srcnn.resize((100, 100))\n",
    "        output_image_srcnn.save(srcnn_path)  # Lưu ảnh\n",
    "        \n",
    "        # output_vdsr = output_vdsr.mul(255.0).to(device).numpy().squeeze(0).squeeze(0)\n",
    "        # output_image_vdsr = np.array([output_vdsr, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "        # output_image_vdsr = np.clip(convert_ycbcr_to_rgb(output_image_vdsr ), 0.0, 255.0).astype(np.uint8)\n",
    "        # output_image_vdsr = Image.fromarray(output_image_vdsr )\n",
    "        # output_image_vdsr = output_image_vdsr.crop(xy)\n",
    "        # output_image_vdsr .save(vdsr_path) \n",
    "        \n",
    "        output_image_vdsr = output_vdsr.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_vdsr = transforms.ToPILImage()(output_image_vdsr)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_vdsr = output_image_vdsr.crop(xy)\n",
    "        output_image_vdsr.resize((100, 100))\n",
    "        output_image_vdsr.save(vdsr_path)  # Lưu ản\n",
    "        \n",
    "        output_image_srresnet = output_srresnet.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image_srresnet = transforms.ToPILImage()(output_image_srresnet)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image_srresnet = output_image_srresnet.crop(xy)\n",
    "        output_image_srresnet.resize((100, 100))\n",
    "        output_image_srresnet.save(srresnet_path)  # Lưu ảnh\n",
    "        \n",
    "        # bicubic = lr_image.resize((600, 600))\n",
    "        bicubic = bicubic.crop(xy)\n",
    "        bicubic.resize((100, 100))\n",
    "        bicubic.save(bicubic_path)\n",
    "        \n",
    "        hr_image_crop = hr_image_copy.crop(xy)\n",
    "        hr_image_crop.resize((100, 100))\n",
    "        hr_image_crop.save(hr_path)\n",
    "        \n",
    "        draw = ImageDraw.Draw(hr_image_copy)\n",
    "        draw.rectangle(xy, outline=\"red\", width=3)\n",
    "        hr_image_copy = hr_image_copy.resize((600, 600))\n",
    "        hr_image_copy.save(f\"{output_image_dir}/{hr_image_file[:-4]}_with_bounding_box.jpg\")\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0img [00:00, ?img/s]/home/robot/anaconda3/envs/pcb/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "/home/robot/anaconda3/envs/pcb/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `StructuralSimilarityIndexMeasure` from `torchmetrics` was deprecated and will be removed in 2.0. Import `StructuralSimilarityIndexMeasure` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n",
      "1068img [05:36,  3.17img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRResNet\n",
      "\n",
      "missinghole_psnr: 26.71\n",
      "\n",
      "mousebite_psnr: 26.78\n",
      "\n",
      "opencircuit_psnr: 26.83\n",
      "\n",
      "short_psnr: 26.72\n",
      "\n",
      "spur_psnr: 26.88\n",
      "\n",
      "spuriouscopper_psnr: 26.64\n",
      "\n",
      "average_psnr: 26.76\n",
      "\n",
      "time process: 336.76\n",
      "\n",
      "missinghole_ssim: 0.75\n",
      "\n",
      "mousebite_ssim: 0.75\n",
      "\n",
      "opencircuit_ssim: 0.75\n",
      "\n",
      "short_ssim: 0.75\n",
      "\n",
      "spur_ssim: 0.76\n",
      "\n",
      "spuriouscopper_ssim: 0.75\n",
      "\n",
      "average_ssim: 0.75\n",
      "\n",
      "time process: 336.76\n",
      "\n",
      "Đã sao chép các file thành công.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for (sub, model) in zip(['VDSR', 'SRCNN'], [vdsr, srcnn]):\n",
    "sub = 'SRResNet'\n",
    "model = srresnet\n",
    "lr_image_dir = f'test1_600x600/images'\n",
    "hr_image_dir = f'test1_600x600/images'\n",
    "output_image_dir = f'output/{sub}/images'\n",
    "os.makedirs(output_image_dir, exist_ok = True)\n",
    "# Duyệt qua các ảnh trong thư mục\n",
    "lr_image_files = os.listdir(lr_image_dir)\n",
    "hr_image_files = os.listdir(hr_image_dir)\n",
    "lr_image_files.sort()\n",
    "hr_image_files.sort()\n",
    "\n",
    "psnr_dict = {\n",
    "    \"mouse_bite\" :[],\n",
    "    \"spur_\":[], \n",
    "    \"missing_hole\":[],\n",
    "    \"short\":[],\n",
    "    \"open_circuit\":[],\n",
    "    \"spurious_copper\":[]\n",
    "\n",
    "}\n",
    "ssim_dict = {\n",
    "    \"mouse_bite\" :[],\n",
    "    \"spur_\":[], \n",
    "    \"missing_hole\":[],\n",
    "    \"short\":[],\n",
    "    \"open_circuit\":[],\n",
    "    \"spurious_copper\":[]\n",
    "\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "transform = transforms.ToTensor()\n",
    "with torch.no_grad():\n",
    "    for lr_image_file, hr_image_file in tqdm(zip(lr_image_files, hr_image_files), unit = 'img'):\n",
    "        # Đường dẫn đến ảnh\n",
    "        lr_image_path = os.path.join(lr_image_dir, lr_image_file)\n",
    "        hr_image_path = os.path.join(hr_image_dir, hr_image_file)\n",
    "        output_image_path = os.path.join(output_image_dir, lr_image_file)\n",
    "\n",
    "        # Tải và chuyển đổi ảnh\n",
    "        lr_image = Image.open(lr_image_path)\n",
    "        hr_image = Image.open(hr_image_path)\n",
    "        lr_image = lr_image.resize((150, 150))\n",
    "        # lr_image = lr_image.resize((600, 600))\n",
    "        lr_image = transform(lr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang CPU\n",
    "        hr_image = transform(hr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang CPU\n",
    "\n",
    "        # Dự đoán\n",
    "        output = model(lr_image)\n",
    "\n",
    "        # Tính toán PSNR\n",
    "        psnr,ssim = calculate_metrics(output, hr_image)\n",
    "        for key in psnr_dict.keys():\n",
    "            if key in lr_image_path:\n",
    "                psnr_dict[key].append(psnr)\n",
    "                ssim_dict[key].append(ssim)\n",
    "                break\n",
    "\n",
    "        # Chuyển đổi tensor đầu ra thành ảnh và lưu\n",
    "        output_image = output.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "        output_image = transforms.ToPILImage()(output_image)  # Chuyển tensor thành ảnh PIL\n",
    "        output_image.save(output_image_path)  # Lưu ảnh\n",
    "avg_psnr = [0, 0, 0, 0, 0, 0]\n",
    "avg_ssim = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "# Tính toán PSNR trung bình\n",
    "avg_psnr[2] = sum(psnr_dict['missing_hole'])/len(psnr_dict['missing_hole']) #missinghole_psnr \n",
    "avg_psnr[0] = sum(psnr_dict['mouse_bite'])/len(psnr_dict['mouse_bite']) #mousebite_psnr\n",
    "avg_psnr[4] = sum(psnr_dict['open_circuit'])/len(psnr_dict['open_circuit']) #opencircuit_psnr\n",
    "avg_psnr[3] = sum(psnr_dict['short'])/len(psnr_dict['short']) #short_psnr\n",
    "avg_psnr[1] = sum(psnr_dict['spur_'])/len(psnr_dict['spur_']) #spur_psnr\n",
    "avg_psnr[5]= sum(psnr_dict['spurious_copper'])/len(psnr_dict['spurious_copper']) #spuriouscopper_psnr \n",
    "average_psnr = sum(avg_psnr)/len(avg_psnr)\n",
    "avg_ssim[2] = sum(ssim_dict['missing_hole'])/len(ssim_dict['missing_hole']) #missinghole_ssim \n",
    "avg_ssim[0] = sum(ssim_dict['mouse_bite'])/len(ssim_dict['mouse_bite']) #mousebite_ssim\n",
    "avg_ssim[4] = sum(ssim_dict['open_circuit'])/len(ssim_dict['open_circuit']) #opencircuit_ssim\n",
    "avg_ssim[3] = sum(ssim_dict['short'])/len(ssim_dict['short']) #short_ssim\n",
    "avg_ssim[1] = sum(ssim_dict['spur_'])/len(ssim_dict['spur_']) #spur_ssim\n",
    "avg_ssim[5]= sum(ssim_dict['spurious_copper'])/len(ssim_dict['spurious_copper']) #spuriouscopper_ssim  \n",
    "average_ssim = sum(avg_ssim)/len(avg_ssim)\n",
    "end = time.time()\n",
    "\n",
    "with open('results.txt', 'a') as f:\n",
    "    f.write(output_image_dir.split('/')[1] + '\\n')\n",
    "    f.write(f'missinghole_psnr: {avg_psnr[2]:.2f}' + '\\n')\n",
    "    f.write(f'mousebite_psnr: {avg_psnr[0]:.2f}' + '\\n')\n",
    "    f.write(f'opencircuit_psnr: {avg_psnr[4]:.2f}' + '\\n')\n",
    "    f.write(f'short_psnr: {avg_psnr[3]:.2f}' + '\\n')\n",
    "    f.write(f'spur_psnr: {avg_psnr[1]:.2f}' + '\\n')\n",
    "    f.write(f'spuriouscopper_psnr: {avg_psnr[5]:.2f}' + '\\n')\n",
    "    f.write(f'average_psnr: {average_psnr:.2f}' + '\\n')\n",
    "    f.write(f'time process: {end - start:.2f}' + '\\n')\n",
    "\n",
    "    f.write(output_image_dir.split('/')[1] + '\\n')\n",
    "    f.write(f'missinghole_psnr: {avg_ssim[2]:.2f}' + '\\n')\n",
    "    f.write(f'mousebite_psnr: {avg_ssim[0]:.2f}' + '\\n')\n",
    "    f.write(f'opencircuit_psnr: {avg_ssim[4]:.2f}' + '\\n')\n",
    "    f.write(f'short_psnr: {avg_ssim[3]:.2f}' + '\\n')\n",
    "    f.write(f'spur_psnr: {avg_ssim[1]:.2f}' + '\\n')\n",
    "    f.write(f'spuriouscopper_psnr: {avg_ssim[5]:.2f}' + '\\n')\n",
    "    f.write(f'average_psnr: {average_ssim:.2f}' + '\\n')\n",
    "    f.write(f'time process: {end - start:.2f}' + '\\n')\n",
    "\n",
    "\n",
    "# tạo dữ liệu cho YOLO\n",
    "print(output_image_dir.split('/')[1] + '\\n')\n",
    "print(f'missinghole_psnr: {avg_psnr[2]:.2f}' + '\\n')\n",
    "print(f'mousebite_psnr: {avg_psnr[0]:.2f}' + '\\n')\n",
    "print(f'opencircuit_psnr: {avg_psnr[4]:.2f}' + '\\n')\n",
    "print(f'short_psnr: {avg_psnr[3]:.2f}' + '\\n')\n",
    "print(f'spur_psnr: {avg_psnr[1]:.2f}' + '\\n')\n",
    "print(f'spuriouscopper_psnr: {avg_psnr[5]:.2f}' + '\\n')\n",
    "print(f'average_psnr: {average_psnr:.2f}' + '\\n')\n",
    "print(f'time process: {end - start:.2f}' + '\\n')\n",
    "print(f'missinghole_ssim: {avg_ssim[2]:.2f}' + '\\n')\n",
    "print(f'mousebite_ssim: {avg_ssim[0]:.2f}' + '\\n')\n",
    "print(f'opencircuit_ssim: {avg_ssim[4]:.2f}' + '\\n')\n",
    "print(f'short_ssim: {avg_ssim[3]:.2f}' + '\\n')\n",
    "print(f'spur_ssim: {avg_ssim[1]:.2f}' + '\\n')\n",
    "print(f'spuriouscopper_ssim: {avg_ssim[5]:.2f}' + '\\n')\n",
    "print(f'average_ssim: {average_ssim:.2f}' + '\\n')\n",
    "print(f'time process: {end - start:.2f}' + '\\n')\n",
    "# Đường dẫn đến thư mục nguồn và đích\n",
    "source_dir = f'test1_600x600/labels'\n",
    "\n",
    "dest = f'output/{sub}/labels'\n",
    "\n",
    "# Tạo thư mục đích nếu chưa tồn tại\n",
    "os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "# Sao chép các file từ thư mục nguồn sang thư mục đích\n",
    "for filename in os.listdir(source_dir):\n",
    "    source_file = os.path.join(source_dir, filename)\n",
    "    file1 = os.path.join(dest, filename)\n",
    "\n",
    "    shutil.copy(source_file, file1)\n",
    "\n",
    "print(\"Đã sao chép các file thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File config.yaml đã được tạo và ghi thành công.\n",
      "WARNING ⚠️ imgsz=[600] must be multiple of max stride 32, updating to [608]\n",
      "Ultralytics 8.3.9 🚀 Python-3.12.4 torch-2.4.0+cu121 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 10971MiB)\n",
      "Model summary (fused): 168 layers, 3,006,818 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/robot/Desktop/pcb/output/SRResNet/labels... 1068 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1068/1068 [00:00<00:00, 2440.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/robot/Desktop/pcb/output/SRResNet/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1068/1068 [00:05<00:00, 198.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1068       2158      0.914      0.759      0.837      0.517\n",
      "            mouse_bite        168        332      0.894      0.762      0.811      0.488\n",
      "                  spur        169        348      0.739      0.787      0.789      0.491\n",
      "          missing_hole        190        379      0.987      0.842      0.932      0.602\n",
      "                 short        184        366      0.967       0.73      0.845      0.541\n",
      "          open_circuit        166        345      0.963       0.84      0.911      0.538\n",
      "       spurious_copper        191        388      0.932      0.593      0.737      0.443\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val38\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.48829,     0.49108,     0.60177,     0.54134,     0.53768,     0.44313])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Nội dung của file YAML\n",
    "# sub = 'VDSR'\n",
    "data = {\n",
    "    'train': f'/home/robot/Desktop/pcb/test1_600x600',\n",
    "    'val': f'./{sub}/images',\n",
    "    'nc': 6,\n",
    "    'names': {\n",
    "        0: 'mouse_bite',\n",
    "        1: 'spur',\n",
    "        2: 'missing_hole',\n",
    "        3: 'short',\n",
    "        4: 'open_circuit',\n",
    "        5: 'spurious_copper'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Tạo và ghi file YAML\n",
    "with open('output/data.yaml', 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False)\n",
    "\n",
    "print(\"File config.yaml đã được tạo và ghi thành công.\")\n",
    "\n",
    "\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# model = YOLO(\"yolov8n.pt\")  # load an official model\n",
    "model = YOLO(\"bestweight_2006.pt\")  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val(data = 'output/data.yaml', batch = 1, imgsz = 600)  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Mở ảnh\n",
    "path = 'benchmark/output/img_008_with_bounding_box.jpg'\n",
    "image = Image.open(path)\n",
    "\n",
    "# Lấy kích thước hiện tại của ảnh\n",
    "width, height = image.size\n",
    "\n",
    "# Tính toán kích thước mới (giữ nguyên tỷ lệ)\n",
    "new_width = 500\n",
    "new_height = int((new_width / width) * height)\n",
    "\n",
    "# Thay đổi kích thước ảnh\n",
    "resized_image = image.resize((new_width, new_height))\n",
    "\n",
    "# Lưu ảnh đã thay đổi kích thước\n",
    "resized_image.save(path)\n",
    "\n",
    "# Hiển thị ảnh mới (tuỳ chọn)\n",
    "resized_image.show()\n"
   ]
>>>>>>> d7845673c23ee57e20936c707617484da8274d31
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
