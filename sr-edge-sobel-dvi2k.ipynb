{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:23:58.495030Z","iopub.status.busy":"2024-09-25T12:23:58.494308Z","iopub.status.idle":"2024-09-25T12:24:03.729522Z","shell.execute_reply":"2024-09-25T12:24:03.728566Z","shell.execute_reply.started":"2024-09-25T12:23:58.494992Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import transforms\n","from torchsummary import summary\n","from torch.utils.data import DataLoader, Dataset\n","import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","from tqdm import tqdm\n","import time\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.731452Z","iopub.status.busy":"2024-09-25T12:24:03.730941Z","iopub.status.idle":"2024-09-25T12:24:03.794823Z","shell.execute_reply":"2024-09-25T12:24:03.793839Z","shell.execute_reply.started":"2024-09-25T12:24:03.731417Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.797602Z","iopub.status.busy":"2024-09-25T12:24:03.797285Z","iopub.status.idle":"2024-09-25T12:24:03.821933Z","shell.execute_reply":"2024-09-25T12:24:03.821064Z","shell.execute_reply.started":"2024-09-25T12:24:03.797577Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import cv2\n","import numpy as np\n","\n","class CannyFilterOpenCV(nn.Module):\n","    def __init__(self, low_threshold=100, high_threshold=200):\n","        super(CannyFilterOpenCV, self).__init__()\n","        self.low_threshold = low_threshold\n","        self.high_threshold = high_threshold\n","\n","    def forward(self, x):\n","        x_np = x.cpu().detach().numpy()\n","        canny_edges_batch = []\n","        for img in x_np:\n","            img_np = img.transpose(1, 2, 0)\n","            img_np = np.uint8(img_np * 255)\n","            canny_edges = cv2.Canny(img_np, self.low_threshold, self.high_threshold)\n","            canny_edges = canny_edges / 255.0\n","            canny_edges_batch.append(canny_edges[np.newaxis, ...])\n","        canny_edges_tensor = torch.from_numpy(np.array(canny_edges_batch)).float().to(x.device)\n","        return canny_edges_tensor\n","    \n","    def get_output_channels(self):\n","        return 1  # Canny filter luôn trả về 1 kênh\n","class SobelFilterOpenCV(nn.Module):\n","    def __init__(self):\n","        super(SobelFilterOpenCV, self).__init__()\n","\n","    def forward(self, x):\n","        x_np = x.cpu().detach().numpy()\n","        sobel_edges_batch = []\n","        for img in x_np:\n","            img_np = img.transpose(1, 2, 0)\n","            img_np = np.uint8(img_np * 255)\n","            sobel_x = cv2.Sobel(img_np, cv2.CV_64F, 1, 0, ksize=3)\n","            sobel_y = cv2.Sobel(img_np, cv2.CV_64F, 0, 1, ksize=3)\n","            sobel_edges = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n","            sobel_edges = cv2.normalize(sobel_edges, None, 0, 1, cv2.NORM_MINMAX)\n","            sobel_edges_batch.append(sobel_edges.transpose(2, 0, 1))\n","        sobel_edges_tensor = torch.from_numpy(np.array(sobel_edges_batch)).float().to(x.device)\n","        return sobel_edges_tensor\n","\n","    def get_output_channels(self, input_channels):\n","        return input_channels  # Sobel filter giữ nguyên số kênh đầu vào\n","class SR(nn.Module):\n","    def __init__(self, num_channels=3, scale_factor=4, use_canny=False, use_sobel=False):\n","        super(SR, self).__init__()\n","        self.scale_factor = scale_factor\n","        self.use_canny = use_canny\n","        self.use_sobel = use_sobel\n","        \n","        self.canny_filter = CannyFilterOpenCV() if use_canny else None\n","        self.sobel_filter = SobelFilterOpenCV() if use_sobel else None\n","        \n","        if use_canny:\n","            additional_channels = 1\n","        if use_sobel:\n","            additional_channels = 3\n","        self.input_conv = nn.Conv2d(num_channels+additional_channels, 64, kernel_size=3, stride=1, padding=1)\n","        \n","        self.residual_layers = nn.Sequential(\n","            *[ResidualCatBlock(64) for _ in range(16)]\n","        )\n","        self.upsample = nn.Sequential(\n","            nn.Conv2d(64, 64*scale_factor**2, kernel_size=3, stride=1, padding=1),\n","            nn.PixelShuffle(scale_factor),\n","            nn.Conv2d(64, num_channels, kernel_size=3, stride=1, padding=1)\n","        )\n","        \n","    def forward(self, x):\n","        edge_maps = []\n","        if self.use_canny:\n","            edge_maps.append(self.canny_filter(x))\n","        if self.use_sobel:\n","            edge_maps.append(self.sobel_filter(x))\n","        \n","        if edge_maps:\n","            x_with_edges = torch.cat([x] + edge_maps, dim=1)\n","        else:\n","            x_with_edges = x\n","        \n","        x = self.input_conv(x_with_edges)\n","        res = self.residual_layers(x)\n","        out = res + x\n","        out = self.upsample(out)\n","        return out\n","\n","class ResidualCatBlock(nn.Module):\n","    def __init__(self, num_channels):\n","        super(ResidualCatBlock, self).__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1)\n","        )\n","        self.conv = nn.Conv2d(num_channels*2, num_channels, kernel_size=1, stride=1)\n","        \n","    def forward(self, x):\n","        out = self.block(x)\n","        out = torch.cat((x, out), 1)\n","        out = self.conv(out)\n","        return x + out\n","\n","# Usage example:\n","# scale = 4\n","# model = SR(scale_factor=scale, use_/=True, use_sobel=True)\n","# model = nn.DataParallel(model).cuda()\n","# summary(model, (3, 150, 150))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.824325Z","iopub.status.busy":"2024-09-25T12:24:03.823331Z","iopub.status.idle":"2024-09-25T12:24:03.833160Z","shell.execute_reply":"2024-09-25T12:24:03.832215Z","shell.execute_reply.started":"2024-09-25T12:24:03.824292Z"},"trusted":true},"outputs":[],"source":["class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = cv2.imread(os.path.join(self.lr_dir, self.lr_files[idx]))\n","        hr_image = cv2.imread(os.path.join(self.hr_dir, self.hr_files[idx]))\n","        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_BGR2RGB)\n","        hr_image = cv2.cvtColor(hr_image, cv2.COLOR_BGR2RGB)\n","        \n","        transform = transforms.Compose([\n","            transforms.ToPILImage(),\n","            transforms.ToTensor()\n","        ])\n","        \n","        lr_image = transform(lr_image)\n","        hr_image = transform(hr_image)\n","        return lr_image, hr_image"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:24:03.835254Z","iopub.status.busy":"2024-09-25T12:24:03.834750Z","iopub.status.idle":"2024-09-25T12:24:03.841602Z","shell.execute_reply":"2024-09-25T12:24:03.840600Z","shell.execute_reply.started":"2024-09-25T12:24:03.835180Z"},"trusted":true},"outputs":[],"source":["# Đường dẫn tới bộ dữ liệu\n","train_lr_dir = 'Train/LR'\n","train_hr_dir = 'Train/HR'\n","valid_lr_dir = 'Test/LR'\n","valid_hr_dir = 'Test/HR'\n","# test_hr_dir  = '/kaggle/input/srdataset/sr_data/test/HR'\n","# test_lr_dir  = '/kaggle/input/srdataset/sr_data/test/LR'\n","\n","# print(torch.cuda.memory_allocated())\n","# print(torch.cuda.memory_reserved())"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:29.152867Z","iopub.status.busy":"2024-09-25T12:33:29.152523Z","iopub.status.idle":"2024-09-25T12:33:30.352211Z","shell.execute_reply":"2024-09-25T12:33:30.351285Z","shell.execute_reply.started":"2024-09-25T12:33:29.152842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["12500\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_89635/4106059255.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  sobelsr.load_state_dict(torch.load('best_sobel_srx4_model.pth'))\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 10.71 GiB of which 87.94 MiB is free. Process 84006 has 850.00 MiB memory in use. Process 88444 has 7.10 GiB memory in use. Including non-PyTorch memory, this process has 1.60 GiB memory in use. Of the allocated memory 1.31 GiB is allocated by PyTorch, and 106.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m optim_sobel \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(sobelsr\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,betas \u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))\n\u001b[1;32m     19\u001b[0m scheduler_sobel \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optim_sobel, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43msobelsr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m510\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m339\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     22\u001b[0m cannysr \u001b[38;5;241m=\u001b[39m SR(scale_factor \u001b[38;5;241m=\u001b[39m scale, use_canny \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[3], line 83\u001b[0m, in \u001b[0;36mSR.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     x_with_edges \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_with_edges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_layers(x)\n\u001b[1;32m     85\u001b[0m out \u001b[38;5;241m=\u001b[39m res \u001b[38;5;241m+\u001b[39m x\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/module.py:1603\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1601\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1603\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1608\u001b[0m     ):\n\u001b[1;32m   1609\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/anaconda3/envs/pcb/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 10.71 GiB of which 87.94 MiB is free. Process 84006 has 850.00 MiB memory in use. Process 88444 has 7.10 GiB memory in use. Including non-PyTorch memory, this process has 1.60 GiB memory in use. Of the allocated memory 1.31 GiB is allocated by PyTorch, and 106.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["from torch.amp import autocast, GradScaler\n","from torchsummary import summary\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","train_dataset = ImageDataset(train_lr_dir, train_hr_dir)\n","train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n","\n","valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir)\n","valid_loader = DataLoader(valid_dataset)\n","print(len(train_loader))\n","# Khởi tạo mô hình, loss function và optimizer\n","scale = 4\n","sobelsr = SR(scale_factor = scale, use_sobel = True).to(device)\n","# sobelsr = nn.DataParallel(sobelsr).to(device)\n","sobelsr.load_state_dict(torch.load('best_sobel_srx4_model.pth'))\n","criterion = nn.MSELoss()\n","optim_sobel = optim.Adam(sobelsr.parameters(), lr=1e-4,betas =(0.9, 0.999))\n","scheduler_sobel = optim.lr_scheduler.StepLR(optim_sobel, step_size=10**5, gamma=0.5)\n","summary(sobelsr.cuda(), input_size=(3, 510, 339), device='cuda')\n","scale = 4\n","cannysr = SR(scale_factor = scale, use_canny = True).to(device)\n","# cannysr = nn.DataParallel(cannysr).to(device)\n","cannysr.load_state_dict(torch.load('best_canny_srx4_model.pth'))\n","criterion = nn.MSELoss()\n","optim_canny = optim.Adam(cannysr.parameters(), lr=1e-4,betas =(0.9, 0.999))\n","scheduler_canny = optim.lr_scheduler.StepLR(optim_canny, step_size=10**5, gamma=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:31.506324Z","iopub.status.busy":"2024-09-25T12:33:31.505734Z","iopub.status.idle":"2024-09-25T12:33:31.511941Z","shell.execute_reply":"2024-09-25T12:33:31.510965Z","shell.execute_reply.started":"2024-09-25T12:33:31.506290Z"},"trusted":true},"outputs":[],"source":["def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-25T12:33:32.155872Z","iopub.status.busy":"2024-09-25T12:33:32.154884Z","iopub.status.idle":"2024-09-25T14:57:54.133761Z","shell.execute_reply":"2024-09-25T14:57:54.132406Z","shell.execute_reply.started":"2024-09-25T12:33:32.155839Z"},"trusted":true},"outputs":[],"source":["num_epochs = 24\n","\n","best_psnr_sobel = float('-inf')\n","best_psnr_canny = float('-inf')\n","torch.cuda.empty_cache()\n","\n","losses_sobel = []\n","losses_canny = []\n","avg_psnr_sobel = []\n","avg_psnr_canny = []\n","\n","val_avg_psnr_sobel = []  # Validation PSNR\n","val_avg_psnr_canny = []\n","\n","patience = 50\n","epochs_no_improve = 0\n","log_file = open('training_log.txt', 'a')\n","scaler = GradScaler()\n","\n","for epoch in range(num_epochs):\n","    sobelsr.train()\n","    cannysr.train()\n","\n","    epoch_loss_sobel = 0\n","    psnr_values_sobel = 0\n","    epoch_loss_canny = 0\n","    psnr_values_canny = 0\n","    start_time = time.time()\n","\n","    # Training loop\n","    for (lr_images, hr_images) in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","        lr_images = lr_images.cuda()\n","        hr_images = hr_images.cuda()\n","\n","        # Sobel SR training\n","        optim_sobel.zero_grad()  \n","        with autocast(device_type='cuda'):\n","            outputs_sobel = sobelsr(lr_images)\n","            loss_sobel = criterion(outputs_sobel, hr_images)\n","        psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","            \n","        scaler.scale(loss_sobel).backward()\n","        scaler.step(optim_sobel)\n","        scaler.update()\n","        scheduler_sobel.step()\n","\n","        # Canny SR training\n","        optim_canny.zero_grad()  \n","        with autocast(device_type='cuda'):\n","            outputs_canny = cannysr(lr_images)\n","            loss_canny = criterion(outputs_canny, hr_images)\n","        psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","        scaler.scale(loss_canny).backward()\n","        scaler.step(optim_canny)\n","        scaler.update()\n","        scheduler_canny.step()\n","        \n","        # Update metrics\n","        epoch_loss_sobel += loss_sobel.item()\n","        psnr_values_sobel += psnr_sobel\n","        epoch_loss_canny += loss_canny.item()\n","        psnr_values_canny += psnr_canny\n","\n","    # Calculate average training metrics\n","    avg_epoch_loss_sobel = epoch_loss_sobel / len(train_loader)\n","    average_psnr_sobel = psnr_values_sobel / len(train_loader)\n","    losses_sobel.append(avg_epoch_loss_sobel)\n","    avg_psnr_sobel.append(average_psnr_sobel)\n","\n","    avg_epoch_loss_canny = epoch_loss_canny / len(train_loader)\n","    average_psnr_canny = psnr_values_canny / len(train_loader)\n","    losses_canny.append(avg_epoch_loss_canny)\n","    avg_psnr_canny.append(average_psnr_canny)\n","\n","    # Validation step\n","    sobelsr.eval()\n","    cannysr.eval()\n","\n","    val_psnr_values_sobel = 0\n","    val_psnr_values_canny = 0\n","\n","    with torch.no_grad():  # No gradients during validation\n","        for (lr_images, hr_images) in tqdm(valid_loader, desc=f'Validation Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","            lr_images = lr_images.cuda()\n","            hr_images = hr_images.cuda()\n","\n","            # Sobel SR validation (no loss, only PSNR)\n","            outputs_sobel = sobelsr(lr_images)\n","            psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","\n","            # Canny SR validation (no loss, only PSNR)\n","            outputs_canny = cannysr(lr_images)\n","            psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","            # Update validation PSNR\n","            val_psnr_values_sobel += psnr_sobel\n","            val_psnr_values_canny += psnr_canny\n","\n","    # Calculate average validation PSNR\n","    val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n","    val_avg_psnr_sobel.append(val_average_psnr_sobel)\n","\n","    val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n","    val_avg_psnr_canny.append(val_average_psnr_canny)\n","\n","    end_time = time.time()\n","\n","    # Logging results\n","    log_string = (f\"Epoch {epoch+1}/{num_epochs}, Loss sobel: {avg_epoch_loss_sobel:.4f}, \"\n","                  f\"Loss canny: {avg_epoch_loss_canny:.4f}, Time training: {end_time - start_time:.4f}s, \"\n","                  f\"PSNR sobel: {average_psnr_sobel:.2f} dB, PSNR canny: {average_psnr_canny:.2f} dB, \"\n","                  f\"Val PSNR sobel: {val_average_psnr_sobel:.2f} dB, Val PSNR canny: {val_average_psnr_canny:.2f} dB\")\n","    print(log_string)\n","    log_file.write(log_string + '\\n')\n","    log_file.flush()\n","\n","    # Save best models based on validation PSNR\n","    if val_average_psnr_sobel > best_psnr_sobel:\n","        best_psnr_sobel = val_average_psnr_sobel\n","        torch.save(sobelsr.state_dict(), f'best_sobel_srx{scale}_model.pth')\n","        print(f\"Saved Sobel SR model with PSNR {best_psnr_sobel:.4f}\")\n","        epochs_no_improve=0\n","    \n","\n","    if val_average_psnr_canny > best_psnr_canny:\n","        best_psnr_canny = val_average_psnr_canny\n","        torch.save(cannysr.state_dict(), f'best_canny_srx{scale}_model.pth')\n","        print(f\"Saved Canny SR model with PSNR {best_psnr_canny:.4f}\")\n","        epochs_no_improve=0\n","    \n","    if (val_average_psnr_sobel < best_psnr_sobel) and (val_average_psnr_canny < best_psnr_canny):\n","        epochs_no_improve+=1\n","    if epochs_no_improve >= patience:\n","        print(f\"PSNR did not improve for 50 epochs. Early stopping at epoch {epoch+1}\")\n","        break\n","    # Clear cache and optionally save models at each epoch\n","    torch.cuda.empty_cache()\n","    torch.save(sobelsr.state_dict(), 'sobel_sr.pth')\n","    torch.save(cannysr.state_dict(), 'canny_sr.pth')\n","\n","# Close log file after training\n","log_file.close()\n","\n","# Plotting results\n","plt.figure(figsize=(12, 10))\n","\n","# Plot loss\n","plt.subplot(2, 1, 1)\n","plt.plot(losses_sobel, label='Sobel SR Loss (Train)')\n","plt.plot(losses_canny, label='Canny SR Loss (Train)')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Training Loss')\n","\n","# Plot PSNR\n","plt.subplot(2, 1, 2)\n","plt.plot(avg_psnr_sobel, label='Sobel SR PSNR (Train)')\n","plt.plot(val_avg_psnr_sobel, label='Sobel SR PSNR (Val)')\n","plt.plot(avg_psnr_canny, label='Canny SR PSNR (Train)')\n","plt.plot(val_avg_psnr_canny, label='Canny SR PSNR (Val)')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR (dB)')\n","plt.legend()\n","plt.title('Average PSNR (Train and Val)')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Testing"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.status.busy":"2024-09-25T12:24:11.229549Z","iopub.status.idle":"2024-09-25T12:24:11.229851Z","shell.execute_reply":"2024-09-25T12:24:11.229713Z","shell.execute_reply.started":"2024-09-25T12:24:11.229700Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Validation Epoch 1/24: 100%|██████████| 10/10 [00:41<00:00,  4.11s/batch]"]},{"name":"stdout","output_type":"stream","text":["27.73695487976074 27.6855562210083\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["cannysr = cannysr.cpu()\n","sobelsr = sobelsr.cpu()\n","sobelsr.eval()\n","cannysr.eval()\n","\n","val_psnr_values_sobel = 0\n","val_psnr_values_canny = 0\n","torch.cuda.empty_cache()\n","with torch.no_grad():  # No gradients during validation\n","        for (lr_images, hr_images) in tqdm(valid_loader, desc=f'Validation Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","                lr_images = lr_images.cpu()\n","                hr_images = hr_images.cpu()\n","\n","                # Sobel SR validation (no loss, only PSNR)\n","                outputs_sobel = sobelsr(lr_images)\n","                psnr_sobel = calculate_psnr(outputs_sobel, hr_images)\n","\n","                # Canny SR validation (no loss, only PSNR)\n","                outputs_canny = cannysr(lr_images)\n","                psnr_canny = calculate_psnr(outputs_canny, hr_images)\n","\n","                # Update validation PSNR\n","                val_psnr_values_sobel += psnr_sobel\n","                val_psnr_values_canny += psnr_canny\n","\n","        # Calculate average validation PSNR\n","        val_average_psnr_sobel = val_psnr_values_sobel / len(valid_loader)\n","\n","        val_average_psnr_canny = val_psnr_values_canny / len(valid_loader)\n","        print(val_average_psnr_canny, val_average_psnr_sobel)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5414450,"sourceId":8989742,"sourceType":"datasetVersion"},{"datasetId":5671931,"sourceId":9356096,"sourceType":"datasetVersion"},{"datasetId":5764801,"sourceId":9478075,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
